import re
from openai import OpenAI

client = OpenAI()

# -------------------------------
#   –ù–∞—Å—Ç—Ä–æ–π–∫–∏
# -------------------------------

FILLERS = [
    "—ç—ç—ç", "—ç", "–Ω—É", "–∫–∞–∫ –±—ã", "—Ç–∏–ø–∞", "–≤ –æ–±—â–µ–º", "–∫–æ—Ä–æ—á–µ",
    "–ø–æ–ª—É—á–∞–µ—Ç—Å—è", "—Å–∫–∞–∂–µ–º —Ç–∞–∫", "—Ç–∞–∫ —Å–∫–∞–∑–∞—Ç—å", "–∑–Ω–∞—á–∏—Ç",
    "—ç—Ç–æ —Å–∞–º–æ–µ", "–Ω–∞–ø—Ä–∏–º–µ—Ä", "–≤–æ—Ç", "–ø–æ–Ω–∏–º–∞–µ—à—å", "–∫–∞–∫ —Å–∫–∞–∑–∞—Ç—å"
]


# -------------------------------
#   –§—É–Ω–∫—Ü–∏–∏ –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
# -------------------------------

def remove_fillers(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª–æ–≤–∞-–ø–∞—Ä–∞–∑–∏—Ç—ã."""
    for filler in FILLERS:
        text = re.sub(rf"\b{filler}\b", "", text, flags=re.IGNORECASE)
    return text


def normalize_spaces(text: str) -> str:
    """–£–¥–∞–ª—è–µ—Ç –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç —Ç–µ–∫—Å—Ç."""
    text = re.sub(r"\s+", " ", text)
    text = text.replace(" .", ".")
    text = text.replace(" ,", ",")
    return text.strip()


def split_into_chunks(text: str, max_chars=4000):
    """–†–∞–∑–¥–µ–ª—è–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ GPT."""
    words = text.split()
    chunks = []
    current = []

    for w in words:
        current.append(w)
        if len(" ".join(current)) > max_chars:
            chunks.append(" ".join(current))
            current = []

    if current:
        chunks.append(" ".join(current))

    return chunks


# -------------------------------
#   GPT –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞
# -------------------------------

def gpt_process(chunk: str) -> dict:
    """
    –í—ã–∑–æ–≤ GPT ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:
    - formatted_text
    - key_ideas
    - terms
    - summary
    - lesson_plan
    """

    prompt = f"""
–û–±—Ä–∞–±–æ—Ç–∞–π —Ç–µ–∫—Å—Ç –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ.

–°–¥–µ–ª–∞–π –ü–Ø–¢–¨ –±–ª–æ–∫–æ–≤:

1) SUMMARY ‚Äî –∫—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –≤ 5‚Äì10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö
2) LESSON_PLAN ‚Äî —É—á–µ–±–Ω—ã–π –ø–ª–∞–Ω –∏–∑ 6‚Äì12 –ø—É–Ω–∫—Ç–æ–≤
3) KEY_IDEAS ‚Äî —Å–ø–∏—Å–æ–∫ –∫–ª—é—á–µ–≤—ã—Ö –∏–¥–µ–π (–º–∏–Ω–∏–º—É–º 10)
4) TERMS ‚Äî —Å–ø–∏—Å–æ–∫ –≤–∞–∂–Ω—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –ø–æ–Ω—è—Ç–∏–π
5) FORMATTED_TEXT ‚Äî —É–ª—É—á—à–µ–Ω–Ω—ã–π —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç:
   - –∞–±–∑–∞—Ü—ã
   - –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∏
   - –ª–æ–≥–∏—á–µ—Å–∫–∏–µ –±–ª–æ–∫–∏
   - –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω–∞—è –ø–æ–¥–∞—á–∞ –±–µ–∑ –ø–∞—Ä–∞–∑–∏—Ç–æ–≤

–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç:

{chunk}
"""

    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
    )

    raw = response.choices[0].message.content

    # –ü–∞—Ä—Å–∏–º 5 —Å–µ–∫—Ü–∏–π
    result = {
        "summary": extract_section(raw, "SUMMARY"),
        "lesson_plan": extract_section(raw, "LESSON_PLAN"),
        "key_ideas": extract_section(raw, "KEY_IDEAS"),
        "terms": extract_section(raw, "TERMS"),
        "formatted_text": extract_section(raw, "FORMATTED_TEXT"),
    }

    return result


def extract_section(text: str, section: str) -> str:
    """–í—ã–Ω–∏–º–∞–µ—Ç –æ—Ç–¥–µ–ª—å–Ω—ã–µ —Å–µ–∫—Ü–∏–∏ –∏–∑ GPT-–æ—Ç–≤–µ—Ç–∞."""
    pattern = rf"{section}:(.*?)(?=\n[A-Z_]+:|$)"
    match = re.search(pattern, text, re.DOTALL)
    return match.group(1).strip() if match else ""


# -------------------------------
#   –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
# -------------------------------

def format_transcript(text: str) -> str:
    """
    –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–∞:
    - –æ—á–∏—Å—Ç–∫–∞
    - –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
    - GPT-—Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ
    - –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö —Å–µ–∫—Ü–∏–π
    """

    # 1. –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –º—É—Å–æ—Ä–∞
    cleaned = remove_fillers(text)
    cleaned = normalize_spaces(cleaned)

    # 2. –î–µ–ª–µ–Ω–∏–µ –Ω–∞ –∫—É—Å–∫–∏
    chunks = split_into_chunks(cleaned)

    summaries = []
    plans = []
    ideas = []
    terms = []
    formatted_parts = []

    # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ –∫—É—Å–∫–∞
    for chunk in chunks:
        result = gpt_process(chunk)

        summaries.append(result["summary"])
        plans.append(result["lesson_plan"])
        ideas.append(result["key_ideas"])
        terms.append(result["terms"])
        formatted_parts.append(result["formatted_text"])

    # 4. –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    final_text = [
        "# üìù –ö—Ä–∞—Ç–∫–æ–µ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
        "\n".join(summaries),

        "\n\n# üìö –ü–ª–∞–Ω —É—Ä–æ–∫–∞",
        "\n".join(plans),

        "\n\n# üí° –ö–ª—é—á–µ–≤—ã–µ –∏–¥–µ–∏",
        "\n".join(ideas),

        "\n\n# üî§ –¢–µ—Ä–º–∏–Ω—ã –∏ –ø–æ–Ω—è—Ç–∏—è",
        "\n".join(terms),

        "\n\n# üìÑ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç",
        "\n\n".join(formatted_parts)
    ]

    return "\n".join(final_text)
